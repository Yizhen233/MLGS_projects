{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from utils import get_mnist_data, get_device\n",
    "from models import ConvNN\n",
    "from training_and_evaluation import evaluate_robustness_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2, part 4: Randomized smoothing certification (20 pt)\n",
    "In this notebook we compare the robustness of the classifiers from Parts 1-3 via randomized smoothing.\n",
    "\n",
    "## Your task\n",
    "Complete the missing code in the respective files, i.e. `models.py`, `training_and_evaluation.py`, `attacks.py`, and this notebook. Make sure that all the functions follow the provided specification, i.e. the output of the function exactly matches the description in the docstring. \n",
    "\n",
    "Specifically, for this part you will have to implement the following functions / classes:  \n",
    "**`training_and_evaluation.py`**:\n",
    "* `evaluate_robustness_smoothing` (20pt)\n",
    "\n",
    "## General remarks\n",
    "\n",
    "Do not add or modify any code outside of the following comment blocks, or where otherwise explicitly stated.\n",
    "``` python\n",
    "##########################################################\n",
    "# YOUR CODE HERE\n",
    "...\n",
    "##########################################################\n",
    "```\n",
    "After you fill in all the missing code, restart the kernel and re-run all the cells in the notebook.\n",
    "\n",
    "The following things are **NOT** allowed:\n",
    "- Using additional `import` statements\n",
    "- Copying / reusing code from other sources (e.g. code by other students)\n",
    "\n",
    "Note that plagiarising even a single project task will make you ineligible for the bonus this semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_testset = get_mnist_data(train=False)\n",
    "device = get_device()\n",
    "\n",
    "model = ConvNN()\n",
    "model.to(device)\n",
    "    \n",
    "num_samples_1 = int(1e3)  # reduce this to 1e2 in case it takes too long, e.g. \n",
    "                          # because you don't have CUDA\n",
    "num_samples_2 = int(1e4)  # reduce this to 1e3 in case it takes too long, e.g. \n",
    "                          # because you don't have CUDA\n",
    "certification_batch_size = int(5e3)  # reduce this to 5e2 if required (e.g. not \n",
    "                                     # enough memory)\n",
    "sigma = 1\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_types = [\"standard_training\", \n",
    "                  \"adversarial_training\", \n",
    "                  \"randomized_smoothing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness certification\n",
    "Here we first load the checkpoints for the base classifiers of the different training methods of Parts 1-3. Then, perform robustness certification of the smooth classifier via randomized smoothing. For this, you need to implement `evaluate_robustness_smoothing` from `training_and_evaluation.py`. Follow the docstring in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16776/3231686403.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                       \u001b[0mnum_samples_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_samples_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                       \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                                       certification_batch_size=certification_batch_size)\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_type\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcertification_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\RCI_pynb\\MLGS\\project_02\\project_02\\training_and_evaluation.py\u001b[0m in \u001b[0;36mevaluate_robustness_smoothing\u001b[1;34m(base_classifier, sigma, dataset, device, num_samples_1, num_samples_2, alpha, certification_batch_size, num_classes)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \"\"\"\n\u001b[0;32m    180\u001b[0m     model = SmoothClassifier(base_classifier=base_classifier, sigma=sigma, \n\u001b[1;32m--> 181\u001b[1;33m                              num_classes=num_classes)\n\u001b[0m\u001b[0;32m    182\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\RCI_pynb\\MLGS\\project_02\\project_02\\models.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, base_classifier, num_classes, sigma)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mvariance\u001b[0m \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mGaussian\u001b[0m \u001b[0mperturbations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \"\"\"\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSmoothClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for training_type in training_types:\n",
    "    model.load_state_dict(torch.load(f\"models/{training_type}.checkpoint\"))\n",
    "    certification_results = \\\n",
    "        evaluate_robustness_smoothing(model, sigma, mnist_testset, device,\n",
    "                                      num_samples_1=num_samples_1,\n",
    "                                      num_samples_2=num_samples_2, \n",
    "                                      alpha=alpha, \n",
    "                                      certification_batch_size=certification_batch_size)\n",
    "    results[training_type] = certification_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness comparison\n",
    "Compare the robustness of the different training types. As we can see, robust training via randomized smoothing leads to the best robustness.\n",
    "\n",
    "Note that the number of certified points will be lower in case you had to reduce the number of samples for performance reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in results.items():\n",
    "    print(f\"{k}: correct_certified {v['correct_certified']}, avg. certifiable \"\n",
    "          f\"radius: {v['avg_radius']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83600a2fe691bd90814c7c1238450c85402d1135b3ae5e9f6ccfc6d792864e74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
